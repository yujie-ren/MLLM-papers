## Vision Language Model Papers
Search Keywords: Vision, Multimodal

## Contents
- 2025
  - [Other](#other)
  - [ICLR-202504](#iclr-202504)
  - [NAACL-202504](#naacl-202504)

## Other


## ICLR-202504
[All Papers](https://openreview.net/group?id=ICLR.cc/2025/Conference#tab-accept-oral) &nbsp;&nbsp;
[Multimodal Model Papers](https://iclr2025.vizhub.ai/?brushed=%255B%255B179.62503051757812%252C18.363710403442383%255D%252C%255B330.3000183105469%252C234.6387176513672%255D%255D)


1. Mechanistic Interpretability Meets Vision Language Models: Insights and Limitations  [[pdf]](https://d2jud02ci9yv69.cloudfront.net/2025-04-28-vlm-understanding-29/blog/vlm-understanding/)  
(THU, 全面介绍了Interpretability & VLM)


## NAACL-202504
[All Papers](https://aclanthology.org/events/naacl-2025/)
1.  EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models  [[pdf]](https://aclanthology.org/2024.emnlp-main.67/)  
    (NJU, Mitigate object hallucination in MLLMs, Gradient ascent by designing losses)
2.  Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps  [[pdf]](https://aclanthology.org/2024.emnlp-main.84/)  
    (⭐️MIT, Detect consistent hallucination, Model's attention on provided context vs its own generations)
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTI5NzMyMzg1NSwtNzMwMTkyNDA3LC0yNT
A1MDM2NzEsNDgyOTkxMDkzLDcwNDY1Mzg3NCwtMTM1MDkyMTIw
NSwxMjc2MTk4Nzk0LDE4NDU2OTI4MDEsLTE2MDU0MTA2MTEsND
c3MDExODgxLDEyMjY1NTI3MzEsNTE2NTc0MjE3LDIwMzkxOTA2
NSw3MjgxNDk4ODldfQ==
-->