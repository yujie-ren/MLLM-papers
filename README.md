## Multimodal Large Language Model Papers
Search Keywords: Vision, Visual, Multimodal

## Contents
- 2025
  - [Other](#other)
  - [ICML-202507](#icml-202507)
  - [ICLR-202504](#iclr-202504)
  - [NAACL-202504](#naacl-202504)

## Other

## ICML-202507
[All Papers](https://openreview.net/group?id=ICML.cc/2025/Conference#tab-accept-oral)

#### MLLM
1. EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents  [[pdf]](https://openreview.net/forum?id=DgGF2LEBPS)  
(UIUC, Benchmark, MLLM, Agent)
2. AffectGPT: A New Dataset, Model, and Benchmark for Emotion Understanding with Multimodal Large Language Models  [[pdf]](https://openreview.net/forum?id=xmbdACI0xu)  
(CAS, Benchmark, MLLM, Emotion understanding)  
3. SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs  [[pdf]](https://openreview.net/forum?id=EVwMw2lVlw)  
(Intel, Benchmark, MLLM, Multimodal RAG)  
4. On Path to Multimodal Generalist: General-Level and General-Bench [[pdf]](https://openreview.net/forum?id=VsJ1K2HV3k)  
(NUS, Multimodal generation, Evaluation framework)  
5. Can MLLMs Reason in Multimodality? EMMA: An Enhanced MultiModal ReAsoning Benchmark  [[pdf]](https://openreview.net/forum?id=v26vwjxOEz)  
(USTC, Benchmark, MLLM Reasoning)  



#### Other
1. Learning dynamics in linear recurrent neural networks  [[pdf]](https://openreview.net/forum?id=KGOcrIWYnx)  
(⭐️ICL, Learning dynamics of RNN, idea for next project)
2. Learning Dynamics in Continual Pre-Training for Large Language Models  [[pdf]](https://openreview.net/forum?id=Vk1rNMl0J1)  
(⭐️UCAS, Learning dynamics of continual pre-training, idea for next project)

## ICLR-202504
[All Papers](https://openreview.net/group?id=ICLR.cc/2025/Conference#tab-accept-oral) &nbsp;&nbsp;
[Multimodal Model Papers](https://iclr2025.vizhub.ai/?brushed=%255B%255B179.62503051757812%252C18.363710403442383%255D%252C%255B330.3000183105469%252C234.6387176513672%255D%255D)

####  MLLM
1. Mechanistic Interpretability Meets Vision Language Models: Insights and Limitations  [[pdf]](https://d2jud02ci9yv69.cloudfront.net/2025-04-28-vlm-understanding-29/blog/vlm-understanding/)  
(Blog, THU, 全面介绍了Interpretability & VLM)
2. Fine-Tuning Token-Based Large Multimodal Models: What Works, What Doesn’t and What's Next  [[pdf]](https://d2jud02ci9yv69.cloudfront.net/2025-04-28-fine-tuning-token-based-large-multimodal-models-86/blog/fine-tuning-token-based-large-multimodal-models/)  
(Blog, Pengfei Liu from SHJT, 探索了VLM Fine-tuning)
3. Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters  [[pdf]](https://openreview.net/forum?id=6VhDQP7WGX)  
(CMU, VLM, 研究了减少visual token和减少LLM参数的trade-off, 没有对比实验。)
4. Dynamic Multimodal Evaluation with Flexible Complexity by Vision-Language Bootstrapping  [[pdf]](https://openreview.net/forum?id=X1OfiRYCLn)  
(SJTU, VLM, VLM evaluation, data contamination)  
5. MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models  [[pdf]](https://openreview.net/forum?id=HnhNRrLPwm)  
(UNC-Chapel Hill, VLM, VLM evaluation)  
6. Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference under Ambiguities  [[pdf]](https://openreview.net/forum?id=84pDoCD4lH)  
(U of Michigan, VLM evaluation)  
7. PhysBench: Benchmarking and Enhancing Vision-Language Models for Physical World Understanding  [[pdf]](https://openreview.net/forum?id=Q6a9W6kzv5)  
(USC, VLM Evaluation)  
8.  Reducing Hallucinations in Large Vision-Language Models via Latent Space Steering  [[pdf]](https://openreview.net/forum?id=LBl7Hez0fF)  
(Stanford, VLM Hallucination)  
9. Vision Language Models are In-Context Value Learners  [[pdf]](https://openreview.net/forum?id=friHAl5ofG)  
(Google, VLM, Robots)  
10. AHA: A Vision-Language-Model for Detecting and Reasoning Over Failures in Robotic Manipulation  [[pdf]](https://openreview.net/forum?id=JVkdSi7Ekg)  
(Nvidia, VLM, Robot, Detect failures)  
11. Teaching Human Behavior Improves Content Understanding Abilities Of VLMs  [[pdf]](https://openreview.net/forum?id=ff2V3UR9sC)  
(Adobe, VLM, Training VLMs to predict receiver behaviors)  
12. NL-Eye: Abductive NLI For Images  [[pdf]](https://openreview.net/forum?id=2zmO1GVT0Y)  
(Technion, VLM Evaluation, Natural language inference in visual domain)  
13. LLaRA: Supercharging Robot Learning Data for Vision-Language Policy [[pdf]](https://openreview.net/forum?id=iVxxgZlXh6)  
(Stony Brook U, VLA model, Motivated by visual instruction tuning)  
14. Failures to Find Transferable Image Jailbreaks Between Vision-Language Models [[pdf]](https://openreview.net/forum?id=wvFnqVVUhN)  
(Stanford, VLM, Image jailbreak)
15. Have the VLMs Lost Confidence? A Study of Sycophancy in VLMs [[pdf]](https://openreview.net/forum?id=E2PFv7ad3p)  
(Fudan U, Sycophancy, Hallucination)  
16. Is Your Video Language Model a Reliable Judge? [[pdf]](https://openreview.net/forum?id=m8yby1JfbU)  
(Iowa State U, Video language models, VLM as a judge)  
17. LLM-wrapper: Black-Box Semantic-Aware Adaptation of Vision-Language Models for Referring Expression Comprehension [[pdf]](https://openreview.net/forum?id=PgXpOOqtyd)  
(Valeo.ai from France, VLM, Referring Expression Comprehension)  
18. Backdooring Vision-Language Models with Out-Of-Distribution Data [[pdf]](https://openreview.net/forum?id=tZozeR3VV7)  
(Stony Brook U, VLM, Backdoor attack)  
19. Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations? [[pdf]](https://openreview.net/forum?id=lCasyP21Bf)  
(⭐️Heidelberg U, Multimodal degree of a VLM)  
20. VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration [[pdf]](https://openreview.net/forum?id=HMrcv7Q4Ub)  
(⭐️UCLA, KV cache in VLM)
21. Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset [[pdf]](https://openreview.net/forum?id=0y3hGn1wOk)  
(UWM, VLM unlearning benchmark)  
22. Re-Aligning Language to Visual Objects with an Agentic Workflow [[pdf]](https://openreview.net/forum?id=MPJ4SMnScw)  
(Nankai U, Language-based object detection, Agentic workflow, VLM hallucination)  
23. BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks [[pdf]](https://openreview.net/forum?id=wwVGZRnAYG)  
(Fudan U, Black-box defense for VLMs against jailbreak attacks)  
24. ImagineNav: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination [[pdf]](https://openreview.net/forum?id=vQFw9ryKyK)  
(Southeast U, Visual navigation, Robots)  
25. Should VLMs be Pre-trained with Image Data? [[pdf]](https://openreview.net/forum?id=Pj4Aid3XqL)  
(⭐️Toyota Research Institute, Pre-train with image or not)  
26. Can We Talk Models Into Seeing the World Differently? [[pdf]](https://openreview.net/forum?id=iVMcYxTiVM)  
(Offenburg U, Vision biases,Shape/texture bias)  
27. Towards Interpreting Visual Information Processing in Vision-Language Models [[pdf]](https://openreview.net/forum?id=chanJGoa7f)  
(NTU, VLM interpretability)  
28. Painting with Words: Elevating Detailed Image Captioning with Benchmark and Alignment Learning [[pdf]](https://openreview.net/forum?id=636M0nNbPs)  
(ByteDance, Image captioning evaluation)  
29. IDA-VLM: Towards Movie Understanding via ID-Aware Large Vision-Language Model [[pdf]](https://openreview.net/forum?id=N5YTixK4F1)  
(UHK, Movie understanding, Associate instances across different scenes)  
30. HAMSTER: Hierarchical Action Models for Open-World Robot Manipulation [[pdf]](https://openreview.net/forum?id=h7aQxzKbq6)  
(Nvidia, Train VLM with off-domain data)  
31. Locality Alignment Improves Vision-Language Models [[pdf]](https://openreview.net/forum?id=qssVptHTPN)  
(Stanford, VLM spatial reasoning, Train with locality alignment)  
32. CogCoM: A Visual Language Model with Chain-of-Manipulations Reasoning [[pdf]](https://openreview.net/forum?id=Fg0eo2AkST)  
(THU, Chain of Manipulations)  
33. Causal Graphical Models for Vision-Language Compositional Understanding [[pdf]](https://openreview.net/forum?id=haJHr4UsQX)  
(University of Modena and Reggio Emilia from Italy, Compositional tasks)  
34. Probabilistic Language-Image Pre-Training [[pdf]](https://openreview.net/forum?id=D5X6nPGFUY)  
(NAVER AI from Korea, CLIP, Probabilistic pretraining)  
35. RA-TTA: Retrieval-Augmented Test-Time Adaptation for Vision-Language Models [[pdf]](https://openreview.net/forum?id=V3zobHnS61)  
(KAIST, Retrieval-augmented test-time adaptation)  
36. Mitigating Spurious Correlations in Zero-Shot Multimodal Models [[pdf]](https://openreview.net/forum?id=UsRKFYR4lM)  
(Purdue U, CLIP, Spurious correlation)  
37. DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models [[pdf]](https://openreview.net/forum?id=VOAMTA8jKu)  
(UIUC, Mathematical reasoning robustness benchmarking)  
38. See It from My Perspective: How Language Affects Cultural Bias in Image Understanding [[pdf]](https://openreview.net/forum?id=Xbl6t6zxZs)  
(Columbia U, Cutural bais in image understanding)  
39. DAMO: Decoding by Accumulating Activations Momentum for Mitigating Hallucinations in Vision-Language Models [[pdf]](https://openreview.net/forum?id=JUr0YOMvZA)  
(U of Maryland, Hallucination, Layer-wise analysis)  
40. Chain-of-region: Visual Language Models Need Details for Diagram Analysis [[pdf]](https://openreview.net/forum?id=M6fYrICcQs)  
(UWM, Visual details, Region decomposion, Scientific diagram analysis)  
41. Mixture of Experts Made Personalized: Federated Prompt Learning for Vision-Language Models [[pdf]](https://openreview.net/forum?id=xiDJaTim3P)  
(U of Pittsburgh, CLIP, Federated learning)  
42. VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents [[pdf]](https://openreview.net/forum?id=zG459X3Xge)  
(THU, VLM-based RAG)  
43. Generating CAD Code with Vision-Language Models for 3D Designs [[pdf]](https://openreview.net/forum?id=BLWaTeucYX)  
(Georgia IT, CAD code verification)  
44. Interpreting and Editing Vision-Language Representations to Mitigate Hallucinations [[pdf]](https://openreview.net/forum?id=94kQgWXojH)  
(⭐️UC Berkely, VLM, Interpretation, Hallucination)  
45. VILA-U: a Unified Foundation Model Integrating Visual Understanding and Generation [[pdf]](https://openreview.net/forum?id=02haSpO453)  
(THU, Unified model, Video, Image, Language understanding and generation)  
46. Enhancing Cognition and Explainability of Multimodal Foundation Models with Self-Synthesized Data [[pdf]](https://openreview.net/forum?id=lHbLpwbEyt)  
(U of Georgia, Fine-grained visual reasoning)  
47. Modality-Specialized Synergizers for Interleaved Vision-Language Generalists [[pdf]](https://openreview.net/forum?id=7UgQjFEadn)  
(Virginia Tech, Vision-Language Generalists, Understanding and generating both text and images)  
48. How Does Vision-Language Adaptation Impact the Safety of Vision Language Models? [[pdf]](https://openreview.net/forum?id=eXB5TCrAu9)  
(⭐️⭐️KAIST, Vision language adaptation, Safety, Model merging)  
49. Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models [[pdf]](https://openreview.net/forum?id=45rvZkJbuX)  
(⭐️⭐️CAS, Vision-language alignment, Safety transfer)



#### Other
1. Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition  [[pdf]](https://openreview.net/forum?id=eHehzSDUFp)  
(KAIST AI, Pretraining过程中参数化知识的整合倾向)
2.  Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance  [[pdf]](https://openreview.net/forum?id=SPS6HzVzyt)  
(CMU，知识冲突中的上下文依赖)
3.  Scaling LLM Test-Time Compute Optimally Can be More Effective than Scaling Parameters for Reasoning  [[pdf]](https://openreview.net/forum?id=4FWAwZtd2n)  
(UC Berkeley，test time computing)
4.  Capturing the Temporal Dependence of Training Data Influence  [[pdf]](https://openreview.net/forum?id=uHLgDEgiS5)  
(Princeton, the influence of specific training data)
5. Data Shapley in One Training Run  [[pdf]](https://openreview.net/forum?id=HD6bWcj87Y)  
(Princeton, the influence of specific training data)
6.  Interpreting Emergent Planning in Model-Free Reinforcement Learning  [[pdf]](https://openreview.net/forum?id=DzGe40glxs)  
(Cambridge, Interpretability, RL agents)  
7.  Unlocking the Power of Function Vectors for Characterizing and Mitigating Catastrophic Forgetting in Continual Instruction Tuning  [[pdf]](https://openreview.net/forum?id=gc8QAQfXv6)  
(USTC, Catastrophic forgetting, Continual learning)  
8. Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Models  [[pdf]](https://openreview.net/forum?id=uAFHCZRmXk)  
(U of Freiburg, CLIP)  
9. Weighted Point Set Embedding for Multimodal Contrastive Learning Toward Optimal Similarity Metric  [[pdf]](https://openreview.net/forum?id=uSz2K30RRd)  
(Sony AI, CLIP)  
10. VLMaterial: Procedural Material Generation with Large Vision-Language Models  [[pdf]](https://openreview.net/forum?id=wHebuIb6IH)  
(MIT, VLM, Computer graphics)  
11. LLaVA-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models  [[pdf]](https://openreview.net/forum?id=oSQiao9GqB)  
(ByteDance, VLM, Multi-image, Video, 3D)  
12. Large-scale and Fine-grained Vision-language Pre-training for Enhanced CT Image Understanding [[pdf]](https://openreview.net/forum?id=nYpPAT4L3D)  
(Alibaba, VLM, Medical image interpretation and diagnosis)  
13. Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders [[pdf]](https://openreview.net/forum?id=Y2RW9EVwhT)  
(Nvidia, VLM, MoE, Systematic comparison)
14. PerturboLLaVA: Reducing Multimodal Hallucinations with Perturbative Visual Training [[pdf]](https://openreview.net/forum?id=j4LITBSUjs)  
(ZJU, VLM hallucination, Incorporating adversarially perturbed text during training)  
15. VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks  [[pdf]](https://openreview.net/forum?id=TE0KOzWYAF)  
(U of Waterloo, Universal multimodal embedding, CLIP)


## NAACL-202504
[All Papers](https://aclanthology.org/events/naacl-2025/)

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTYwMTk0MzM2OSwxODA4MjY1Mjg5LC00ND
g3Nzg3MjUsNjE4MzA1NDE3LDE1NDI5NDI0ODQsLTEzNTM4NDQx
MjksLTI5NDc2ODE3Niw5NjQ0NDI2MTYsMTgzNzU2ODE0Nyw2Nj
I2NDUwMzcsMTM4ODgwOTM0OSwxMzQwMDM1NTE2LDIwMTc2MzM5
MDQsMzk3NzA2MDAzLC0xNjIzNzI4MjIwLDExNDQwNjYwMDksMT
g4NjgwODk2NiwtMjg2MTI0Njc2LDg5MDk1MDA5MiwxMTAzODU1
MThdfQ==
-->