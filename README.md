## Multimodal Large Language Model Papers
Search Keywords: Vision, Visual, Multimodal

## Contents
- 2025
  - [Other](#other)
  - [ICLR-202504](#iclr-202504)
  - [NAACL-202504](#naacl-202504)

## Other


## ICLR-202504
[All Papers](https://openreview.net/group?id=ICLR.cc/2025/Conference#tab-accept-oral) &nbsp;&nbsp;
[Multimodal Model Papers](https://iclr2025.vizhub.ai/?brushed=%255B%255B179.62503051757812%252C18.363710403442383%255D%252C%255B330.3000183105469%252C234.6387176513672%255D%255D)


1. Mechanistic Interpretability Meets Vision Language Models: Insights and Limitations  [[pdf]](https://d2jud02ci9yv69.cloudfront.net/2025-04-28-vlm-understanding-29/blog/vlm-understanding/)  
(Blog, THU, 全面介绍了Interpretability & VLM)
2. Fine-Tuning Token-Based Large Multimodal Models: What Works, What Doesn’t and What's Next  [[pdf]](https://d2jud02ci9yv69.cloudfront.net/2025-04-28-fine-tuning-token-based-large-multimodal-models-86/blog/fine-tuning-token-based-large-multimodal-models/)  
(Blog, Pengfei Liu from SHJT, 探索了VLM Fine-tuning)
3. Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters  [[pdf]](https://openreview.net/pdf?id=6VhDQP7WGX)  
(CMU, 研究了减少visual token和减少LLM参数的trade-off, 没有对比实验。)
4. Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition  [[pdf]](https://openreview.net/forum?id=eHehzSDUFp)  
(KAIST AI, Pretraining过程中参数化知识的整合倾向)


## NAACL-202504
[All Papers](https://aclanthology.org/events/naacl-2025/)

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE1ODY4NDIzODcsMjYwOTEzNTQyLDExOT
UyMzA2NDIsMTY2NzA5NzQxMiwxODI2OTE5MDI5LC0xNzI2NDcx
NzYxLC0xNTUxNzI5NTcyLDIwMzkwMzQwOTYsLTEzMDMwNDU0ND
gsMTI5NzMyMzg1NSwtNzMwMTkyNDA3LC0yNTA1MDM2NzEsNDgy
OTkxMDkzLDcwNDY1Mzg3NCwtMTM1MDkyMTIwNSwxMjc2MTk4Nz
k0LDE4NDU2OTI4MDEsLTE2MDU0MTA2MTEsNDc3MDExODgxLDEy
MjY1NTI3MzFdfQ==
-->